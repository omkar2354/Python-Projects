ğŸ“š Books Web Scraper (Python Project)

A complete Python web-scraping project that extracts book details from BooksToScrape.com using Requests, BeautifulSoup, and CSV export.
The scraper is designed to be fast, reliable, and structured, with retry logic, delays, page navigation, and detailed product extraction.

ğŸš€ Project Overview

This project scrapes all books from the website:

ğŸ”¹ Title
ğŸ”¹ Price
ğŸ”¹ Availability
ğŸ”¹ Rating (1â€“5)
ğŸ”¹ UPC
ğŸ”¹ Product description
ğŸ”¹ Category
ğŸ”¹ Product page URL
ğŸ”¹ Image URL
ğŸ”¹ Timestamp (scraped_at)

All scraped data is saved into a structured CSV file inside the output/ folder.

ğŸ§  Features
âœ” 1. Page-by-page scraping

The scraper automatically moves through all pages using the â€œNextâ€ pagination.

âœ” 2. Product-level deep scraping

Each bookâ€™s product page is opened and details like UPC, description, category, and image URL are extracted.

âœ” 3. Anti-blocking behaviour

Random delays between requests

Custom User-Agent

Automatic retries on timeouts

âœ” 4. Progress Bar

Uses tqdm to show real-time scraping progress.

âœ” 5. Clean CSV Output

All fields are stored in:

output/books.csv

ğŸ› ï¸ Technologies Used

Python 3

requests

BeautifulSoup4

tqdm

csv

urllib

dateutil

os

random

ğŸ“¦ Project Structure
Book-Scraper/
â”‚
â”œâ”€â”€ scrape_books.py        # Main scraping script
â”œâ”€â”€ output/
â”‚   â””â”€â”€ books.csv          # Scraped data (auto-generated)
â””â”€â”€ README.md

ğŸ”§ How to Run the Scraper
1ï¸âƒ£ Install dependencies
pip install requests beautifulsoup4 python-dateutil tqdm

2ï¸âƒ£ Run the script
python scrape_books.py

3ï¸âƒ£ After completion

Your extracted data will appear here:

output/books.csv

ğŸ“ CSV Output Fields
Field	Description
title	Book name
price	Price of the book
availability	In stock / Out of stock
rating	Star rating (1â€“5)
product_page_url	Direct link to product
upc	Product UPC code
desc	Book description
category	Genre/category
img_url	Cover image URL
scraped_at	Local timestamp
ğŸ” How the Script Works (Short Summary)

Sends GET request to each page

Parses books listed

Extracts basic details

Opens each bookâ€™s detail page

Extracts deep metadata

Writes everything to CSV

Moves to the next page until no pages remain

The scraper includes robust error handling and retry logic to avoid failures.

ğŸ Final Output

You get a high-quality CSV dataset with all books from the website â€” perfect for:

âœ” Data analysis
âœ” Machine learning
âœ” Portfolio projects
âœ” Practice datasets
âœ” ETL tasks
